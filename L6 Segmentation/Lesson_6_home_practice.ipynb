{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBY6WZHNU2Ap"
   },
   "source": [
    "# Подготовка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_NBAv0Lk_JiR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'clothing-co-parsing'...\n",
      "remote: Enumerating objects: 4234, done.\u001b[K\n",
      "remote: Total 4234 (delta 0), reused 0 (delta 0), pack-reused 4234\u001b[K\n",
      "Receiving objects: 100% (4234/4234), 124.59 MiB | 854.00 KiB/s, done.\n",
      "Resolving deltas: 100% (1100/1100), done.\n",
      "Updating files: 100% (4202/4202), done.\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/bearpaw/clothing-co-parsing.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GH--hMAO-3UZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy import io\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверить устройства для кераса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11283811861863816198\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xBdCVgw_VNkK"
   },
   "source": [
    "# Функции для визуализации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "b4KUA7PDVQJv"
   },
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]\n",
    "\n",
    "def show_predictions(model, dataset=None, num=1):\n",
    "    if dataset:\n",
    "        for image, mask in dataset.take(num):\n",
    "            pred_mask = model.predict(image)\n",
    "            display([image[0], mask[0], create_mask(pred_mask)])\n",
    "    else:\n",
    "        display([sample_image, sample_mask,\n",
    "             create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRHnOaKDVDB4"
   },
   "source": [
    "# Загрузка датасета и обработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MfUa1DoS_CeK"
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = 'clothing-co-parsing/photos/'\n",
    "MASKS_PATH = 'clothing-co-parsing/annotations/pixel-level/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FAXq9DO4_M3H"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # scale values to [0,1]\n",
    "    image = image/255.0\n",
    "    # resize image\n",
    "    image = tf.image.resize(image, (128,128))\n",
    "    return image \n",
    "     \n",
    "\n",
    "def preprocess_mask(mask):\n",
    "    mask = tf.expand_dims(mask, axis=-1)\n",
    "    mask = tf.image.resize(mask, (128,128))\n",
    "    # будем использовать бинарную классификацию - фон и человек\n",
    "    # для этого фон, закодированный нулем, оставим нулевым\n",
    "    # все остальное будет равно единице\n",
    "    mask = tf.cast(mask != 0, tf.uint8)\n",
    "    return mask  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Q0cheAm9U2q4"
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "masks = []\n",
    "\n",
    "for mask_filename in os.listdir(MASKS_PATH):\n",
    "    image_filename = mask_filename[:-4] + '.jpg'\n",
    "    image = img_to_array(load_img(DATASET_PATH + image_filename))\n",
    "    images.append(preprocess_image(image))\n",
    "\n",
    "    mask_file = io.loadmat(MASKS_PATH + mask_filename)\n",
    "    mask = tf.convert_to_tensor(mask_file['groundtruth']) \n",
    "    masks.append(preprocess_mask(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "t_lTXebrVHCZ"
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(images, masks,\\\n",
    "                                                 test_size=0.2, random_state=0)\n",
    "sample_image, sample_mask = train_X[0], train_Y[0]\n",
    "\n",
    "train_X = tf.data.Dataset.from_tensor_slices(train_X)\n",
    "test_X = tf.data.Dataset.from_tensor_slices(test_X)\n",
    "train_Y = tf.data.Dataset.from_tensor_slices(train_Y)\n",
    "test_Y = tf.data.Dataset.from_tensor_slices(test_Y)\n",
    "\n",
    "train = tf.data.Dataset.zip((train_X, train_Y))\n",
    "test = tf.data.Dataset.zip((test_X, test_Y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "tiXWJRQbZgA0"
   },
   "outputs": [],
   "source": [
    "# функции для аугментации \n",
    "\n",
    "# яркость\n",
    "def brightness(img, mask):\n",
    "    img = tf.image.adjust_brightness(img, 0.1)\n",
    "    return img, mask\n",
    "\n",
    "# оттенок\n",
    "def hue(img, mask):\n",
    "    img = tf.image.adjust_hue(img, -0.1)\n",
    "    return img, mask\n",
    "\n",
    "# отзеркаливание по горизонтали\n",
    "def flip_horisontal(img, mask):\n",
    "    img = tf.image.flip_left_right(img)\n",
    "    mask = tf.image.flip_left_right(mask)\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "RwKfwRYGappc"
   },
   "outputs": [],
   "source": [
    "# последовательно применяем аугментации\n",
    "train = train.concatenate(train.map(brightness))\n",
    "train = train.concatenate(train.map(hue))\n",
    "train = train.concatenate(train.map(flip_horisontal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1B2aZCyjcAwv",
    "outputId": "47d41767-2831-4a55-e3eb-3fde31e4678f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6424"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7bKUzjUFU7Jc"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 500\n",
    "train = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "train = train.prefetch(buffer_size=BUFFER_SIZE)\n",
    "test = test.batch(BATCH_SIZE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Su97HsPtdT-A"
   },
   "source": [
    "далее обучайте на датасете train, для валидации используйте датасет test аналогично как на занятии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 128, 128, 1), dtype=tf.uint8, name=None))>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.take(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 12:52:44.938090: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "sample_image, sample_mask = next(iter(train.take(1).cache().repeat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected image array to have rank 3 (single image). Got array with shape: (32, 128, 128, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(display_list)\u001b[0m\n\u001b[1;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(display_list), i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(title[i])\n\u001b[0;32m----> 8\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisplay_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      9\u001b[0m     plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/image_utils.py:226\u001b[0m, in \u001b[0;36marray_to_img\u001b[0;34m(x, data_format, scale, dtype)\u001b[0m\n\u001b[1;32m    224\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 226\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected image array to have rank 3 (single image). \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    227\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGot array with shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_format \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannels_first\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannels_last\u001b[39m\u001b[38;5;124m'\u001b[39m}:\n\u001b[1;32m    230\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid data_format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected image array to have rank 3 (single image). Got array with shape: (32, 128, 128, 3)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAANeCAYAAACoJPHTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAaW0lEQVR4nO3df4zteV3f8dfbXbcKWKByNbo/ZNuu4sZIo1cwpipWW3cxZjUhLaBSqcmWKtY/Ibb+qKatNjZVA3SzpVuqRlerVNYGwSYNUotbudvCwkog10XY61JZfoiKLduFT/+Ys3UY7jJnLjP3vuA8Hskkc873M2fe95N753m/3zlzZtZaAYBGn3apBwCARyJSANQSKQBqiRQAtUQKgFoiBUAtkQKglkjxKW9mfn9mvuEifJ4fnpmfa5gFPlWIFAC1RIqdMjPfOTO/NTM/MTPvn5m3z8yN+46/Zmb++cz8zsx8YGZeMTN/aXPsaTNz7sDj/f7MfMPM3JDk+5P8nZn505l545az/LeZ+Vcz80czc+/MfNXm/vtm5t0z83f3rf+mmfmfM/PHm+M/fODxnjMz75iZ987MD+w/a5uZT5uZF87M722O/9LDfy5oJlLsoqcmeWuSJyT5F0n+7czMvuPPSfL3knx+koeS/PRhD7jWelWSf5bkF9daj1lrPfkIs9yd5LOT/HyS25N8RZK/muTbk7xoZh6zWfvBzWyPS/JNSf7BzHxLkszM9UlekuTbknxekscmuXLf5/mHSb4lyddu/lzvT/LiLWeES0ak2EXvWGv9m7XWh5P8++x9Uf/cfcd/dq315rXWB5P8QJK/PTOXndAsb19r/bvNLL+Y5OokP7LW+tBa6zeSPJi9YGWt9Zq11pvWWh9Za92d5BeyF50keUaSX1tr/dZa68EkP5hk/wtz/v0k/2itdW6t9aEkP5zkGTNz+Qn9ueBY+AvKLvpfD7+z1vqzzUnUY/Ydv2/f++9I8unZO+s6CX+47/3/vZnp4H2PSZKZeWqSH0vyJUmuSPIXkvyHzbrPz765N3+u9+57nC9I8h9n5iP77vtw9uL8B8fyJ4ET4EwKPtbV+96/Jsn/TfKe7F1ue9TDBzZnV6f2rT3pXynw80nuSHL1WuuxSW5J8vBlyncluWrfbJ+ZvUuID7svyY1rrcfte/uMtZZAUU2k4GN9+8xcPzOPSvIjSX55cznubUk+Y/MEhk9P8o+zdzbzsD9M8sSZOal/V5+V5H1rrf8zM09J8ux9x345yTdvnnhxRZJ/kj8PWLIXtH86M1+QJDNzamZuOqE54diIFHysn03ysuxdFvyM7D3pIGutDyT57iQvzd4lsg8m2f9sv4cvvb13Zv7HCcz13Ul+ZGb+JHvfc/qlhw+ste5J8r3Ze+LFu5L8SZJ3J/nQZslPZe8s7Dc2H39n9p60AdXGLz2EPzczr0nyc2utl17qWT4Rm2cE/lGS69Zab7/E48AFcyYFnyJm5ptn5lEz8+gkP5HkTUl+/9JOBZ+YQyM1M7dtfqjwzY9wfGbmp2fm7MzcPTNfdvxjAlu4Kcn9m7frkjxzuVTCJ7lDL/fNzNck+dMkP7PW+pLzHH969q6FPz1717h/aq3lWjcAn7BDz6TWWq9N8r6Ps+Sm7AVsrbXuTPK4mfm84xoQgN11HD/Me2U++ocfz23ue9fBhTNzc5Kbk+TRj370lz/pSU86hk8PQLu77rrrPWutU4ev/GjHEak5z33nvYa41ro1ya1Jcvr06XXmzJlj+PQAtJuZd1zIxx3Hs/vO5aN/Qv+q7H3jFgA+IccRqTuSPGfzLL+vTPKBtdbHXOoDgKM69HLfzPxCkqclecLmd+n8UPZecDNrrVuSvDJ7z+w7m+TPkjz3pIYFYLccGqm11rMOOb6SfM+xTQQAG15xAoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQK2tIjUzN8zMW2fm7My88DzHHzszvzYzb5yZe2bmucc/KgC75tBIzcxlSV6c5MYk1yd51sxcf2DZ9yT53bXWk5M8Lcm/nJkrjnlWAHbMNmdST0lydq1171rrwSS3J7npwJqV5LNmZpI8Jsn7kjx0rJMCsHO2idSVSe7bd/vc5r79XpTki5Pcn+RNSb5vrfWRgw80MzfPzJmZOfPAAw9c4MgA7IptIjXnuW8duP2NSd6Q5POT/LUkL5qZv/gxH7TWrWut02ut06dOnTriqADsmm0idS7J1ftuX5W9M6b9npvk5WvP2SRvT/Kk4xkRgF21TaRen+S6mbl282SIZya548Cadyb5+iSZmc9N8kVJ7j3OQQHYPZcftmCt9dDMPD/Jq5NcluS2tdY9M/O8zfFbkvxokpfNzJuyd3nwBWut95zg3ADsgEMjlSRrrVcmeeWB+27Z9/79Sf7W8Y4GwK7zihMA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqbRWpmblhZt46M2dn5oWPsOZpM/OGmblnZn7zeMcEYBddftiCmbksyYuT/M0k55K8fmbuWGv97r41j0vykiQ3rLXeOTOfc0LzArBDtjmTekqSs2ute9daDya5PclNB9Y8O8nL11rvTJK11ruPd0wAdtE2kboyyX37bp/b3LffFyZ5/My8ZmbumpnnHNeAAOyuQy/3JZnz3LfO8zhfnuTrk3xmkt+emTvXWm/7qAeauTnJzUlyzTXXHH1aAHbKNmdS55Jcve/2VUnuP8+aV621PrjWek+S1yZ58sEHWmvdutY6vdY6ferUqQudGYAdsU2kXp/kupm5dmauSPLMJHccWPOKJF89M5fPzKOSPDXJW453VAB2zaGX+9ZaD83M85O8OsllSW5ba90zM8/bHL9lrfWWmXlVkruTfCTJS9dabz7JwQH41DdrHfz20sVx+vTpdebMmUvyuQG4uGbmrrXW6aN+nFecAKCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUGurSM3MDTPz1pk5OzMv/DjrvmJmPjwzzzi+EQHYVYdGamYuS/LiJDcmuT7Js2bm+kdY9+NJXn3cQwKwm7Y5k3pKkrNrrXvXWg8muT3JTedZ971JfiXJu49xPgB22DaRujLJfftun9vc9//NzJVJvjXJLcc3GgC7bptIzXnuWwdu/2SSF6y1PvxxH2jm5pk5MzNnHnjggS1HBGBXXb7FmnNJrt53+6ok9x9YczrJ7TOTJE9I8vSZeWit9av7F621bk1ya5KcPn36YOgA4KNsE6nXJ7luZq5N8gdJnpnk2fsXrLWuffj9mXlZkv90MFAAcFSHRmqt9dDMPD97z9q7LMlta617ZuZ5m+O+DwXAidjmTCprrVcmeeWB+84bp7XWd37iYwGAV5wAoJhIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqLVVpGbmhpl568ycnZkXnuf4t83M3Zu3183Mk49/VAB2zaGRmpnLkrw4yY1Jrk/yrJm5/sCytyf52rXWlyb50SS3HvegAOyebc6knpLk7Frr3rXWg0luT3LT/gVrrdettd6/uXlnkquOd0wAdtE2kboyyX37bp/b3PdIvivJr5/vwMzcPDNnZubMAw88sP2UAOykbSI157lvnXfhzNdlL1IvON/xtdata63Ta63Tp06d2n5KAHbS5VusOZfk6n23r0py/8FFM/OlSV6a5Ma11nuPZzwAdtk2Z1KvT3LdzFw7M1ckeWaSO/YvmJlrkrw8yXestd52/GMCsIsOPZNaaz00M89P8uoklyW5ba11z8w8b3P8liQ/mOSzk7xkZpLkobXW6ZMbG4BdMGud99tLJ+706dPrzJkzl+RzA3BxzcxdF3Ly4hUnAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1BIpAGqJFAC1RAqAWiIFQC2RAqCWSAFQS6QAqCVSANQSKQBqiRQAtUQKgFoiBUAtkQKglkgBUEukAKglUgDUEikAaokUALVECoBaIgVALZECoJZIAVBLpACoJVIA1NoqUjNzw8y8dWbOzswLz3N8ZuanN8fvnpkvO/5RAdg1h0ZqZi5L8uIkNya5PsmzZub6A8tuTHLd5u3mJP/6mOcEYAdtcyb1lCRn11r3rrUeTHJ7kpsOrLkpyc+sPXcmedzMfN4xzwrAjrl8izVXJrlv3+1zSZ66xZork7xr/6KZuTl7Z1pJ8qGZefORpt1tT0jynks9xCcR+3U09uvo7NnRfNGFfNA2kZrz3LcuYE3WWrcmuTVJZubMWuv0Fp+f2K+jsl9HY7+Ozp4dzcycuZCP2+Zy37kkV++7fVWS+y9gDQAcyTaRen2S62bm2pm5Iskzk9xxYM0dSZ6zeZbfVyb5wFrrXQcfCACO4tDLfWuth2bm+UleneSyJLette6Zmedtjt+S5JVJnp7kbJI/S/LcLT73rRc89W6yX0djv47Gfh2dPTuaC9qvWetjvnUEABW84gQAtUQKgFonHikvqXQ0W+zXt2326e6Zed3MPPlSzNnisP3at+4rZubDM/OMizlfm232a2aeNjNvmJl7ZuY3L/aMTbb49/jYmfm1mXnjZr+2+X78p6yZuW1m3v1IPwN7QV/v11on9pa9J1r8XpK/nOSKJG9Mcv2BNU9P8uvZ+1mrr0zy309ypua3Lffrq5I8fvP+jfbr4+/XvnX/JXtP8HnGpZ67eb+SPC7J7ya5ZnP7cy713OX79f1Jfnzz/qkk70tyxaWe/RLu2dck+bIkb36E40f+en/SZ1JeUuloDt2vtdbr1lrv39y8M3s/k7artvn7lSTfm+RXkrz7Yg5XaJv9enaSl6+13pkka61d3rNt9msl+ayZmSSPyV6kHrq4Y/ZYa702e3vwSI789f6kI/VIL5d01DW74qh78V3Z+1/Jrjp0v2bmyiTfmuSWizhXq23+fn1hksfPzGtm5q6Zec5Fm67PNvv1oiRfnL0XL3hTku9ba33k4oz3SenIX++3eVmkT8SxvaTSjth6L2bm67IXqb9+ohN122a/fjLJC9ZaH977z+5O22a/Lk/y5Um+PslnJvntmblzrfW2kx6u0Db79Y1J3pDkbyT5K0n+88z817XWH5/wbJ+sjvz1/qQj5SWVjmarvZiZL03y0iQ3rrXee5Fma7TNfp1OcvsmUE9I8vSZeWit9asXZcIu2/57fM9a64NJPjgzr03y5CS7GKlt9uu5SX5s7X3D5ezMvD3Jk5L8zsUZ8ZPOkb/en/TlPi+pdDSH7tfMXJPk5Um+Y0f/d7vfofu11rp2rfXEtdYTk/xyku/e0UAl2/17fEWSr56Zy2fmUdn7jQdvuchztthmv96ZvbPOzMznZu+Vvu+9qFN+cjny1/sTPZNaJ/eSSp+SttyvH0zy2Ulesjk7eGjt6Csxb7lfbGyzX2utt8zMq5LcneQjSV661trJX6mz5d+vH03yspl5U/YuZb1grbWzv75jZn4hydOSPGFmziX5oSSfnlz413sviwRALa84AUAtkQKglkgBUEukAKglUgDUEikAaokUALX+H/DyBsK+r41MAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Lesson 6 - home practice.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
